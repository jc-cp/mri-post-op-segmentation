{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n",
      "12.1\n",
      "90100\n",
      "True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import sys\n",
    "sys.path.append(\"/home/jc053/GIT/mri-post-op-segmentation/\")\n",
    "from utils.helper_functions import run_command, evaluate_fold, log_metrics_to_wandb, prepare_nnunet_data\n",
    "from src.trainer_nnUnet import nnUNetTrainerV2_WandB\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set config & environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TASK_NAME = \"BraTS2024_PostSurgery\"\n",
    "TASK_ID = 901  # Assign a unique task ID\n",
    "BASE_DIR = Path(\"/mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset\")  # Adjust this path\n",
    "NUM_GPUs = 2\n",
    "WANDB_PROJECT = \"BraTS2024_nnUNet\"\n",
    "MODEL = \"nnUNet_test\"\n",
    "\n",
    "# Set environment variables\n",
    "NNUNET_RAW = BASE_DIR / MODEL / \"nnUNet_raw_data_base\" / \"nnUNet_raw_data\" / f\"Task{TASK_ID}_{TASK_NAME}\"\n",
    "os.environ[\"nnUNet_raw_data_base\"] = str(BASE_DIR / MODEL / \"nnUNet_raw_data_base\")\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(BASE_DIR / MODEL / \"nnUNet_preprocessed\")\n",
    "os.environ[\"RESULTS_FOLDER\"] = str(BASE_DIR / MODEL / \"nnUNet_trained_models\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Data Preparation (if data is not prepared already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_nnunet_data(NNUNET_RAW, BASE_DIR, TASK_NAME, max_cases=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Planning and Preprocessing (if not done already, to be in the nnUnet configuration style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = run_command(f\"nnUNet_plan_and_preprocess -t {TASK_ID} --verify_dataset_integrity\")\n",
    "if not success:\n",
    "   print(\"Dataset planning and preprocessing failed.\")\n",
    "   exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Training (3D fullres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jc053/GIT/mri-post-op-segmentation/src/wandb/run-20240919_204421-le0ktl3h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bwh-harvard/BraTS2024_nnUNet/runs/le0ktl3h' target=\"_blank\">BraTS2024_PostSurgery_run</a></strong> to <a href='https://wandb.ai/bwh-harvard/BraTS2024_nnUNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bwh-harvard/BraTS2024_nnUNet' target=\"_blank\">https://wandb.ai/bwh-harvard/BraTS2024_nnUNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bwh-harvard/BraTS2024_nnUNet/runs/le0ktl3h' target=\"_blank\">https://wandb.ai/bwh-harvard/BraTS2024_nnUNet/runs/le0ktl3h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: 'T1', 1: 'T1ce', 2: 'T2', 3: 'FLAIR'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([138, 168, 137]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': np.False_, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/nnUNet_preprocessed/Task901_BraTS2024_PostSurgery/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2024-09-19 20:44:23.703833: Using splits from existing split file: /mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/nnUNet_preprocessed/Task901_BraTS2024_PostSurgery/splits_final.pkl\n",
      "2024-09-19 20:44:23.704195: The split file contains 5 splits.\n",
      "2024-09-19 20:44:23.704226: Desired fold for training: 0\n",
      "2024-09-19 20:44:23.704257: This split has 8 training and 2 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2024-09-19 20:44:24.851706: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=WANDB_PROJECT, name=f\"{TASK_NAME}_run\")\n",
    "\n",
    "# # Log configuration\n",
    "wandb.config.update({\n",
    "    \"task_name\": TASK_NAME,\n",
    "    \"task_id\": TASK_ID,\n",
    "    \"num_gpus\": NUM_GPUs\n",
    "})\n",
    "\n",
    "success = run_command(f\"CUDA_VISIBLE_DEVICES=0,1 nnUNet_train 3d_fullres nnUNetTrainerV2 {TASK_ID} 0\")\n",
    "if not success:\n",
    "    wandb.finish()\n",
    "    exit(1)\n",
    "\n",
    "# Evaluate and log metrics\n",
    "TRAINED_MODELS_DIR = BASE_DIR / MODEL / \"nnUNet_trained_models\" / \"nnUNet\" / \"3d_fullres\" / f\"Task{TASK_ID}_{TASK_NAME}\"\n",
    "output_fold = TRAINED_MODELS_DIR / \"fold_0\"\n",
    "dsc, hd95 = evaluate_fold(str(output_fold), str(BASE_DIR))\n",
    "log_metrics_to_wandb({\"3d_fullres_DSC\": dsc, \"3d_fullres_HD95\": hd95}, step=0)\n",
    "\n",
    "# Log final model files\n",
    "model_artifact = wandb.Artifact(f\"{TASK_NAME}_model\", type=\"model\")\n",
    "model_artifact.add_dir(str(TRAINED_MODELS_DIR / \"fold_0\"))\n",
    "wandb.log_artifact(model_artifact)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/nnUNet_trained_models/nnUNet/3d_fullres/Task901_BraTS2024_PostSurgery/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 4 input modalities for each image\n",
      "Found 10 unique case ids, here are some examples: ['02834_100' '02773_101' '00553_100' '02135_101' '02089_101' '00553_101'\n",
      "'02089_101' '02834_101' '00553_100' '00553_101']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 10\n",
      "number of cases that still need to be predicted: 10\n",
      "emptying cuda cache\n",
      "loading parameters for folds, [0]\n",
      "Error executing command: nnUNet_predict -i /mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/nnUNet_raw_data_base/nnUNet_raw_data/Task901_BraTS2024_PostSurgery/imagesTs -o /mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/inference_results -t 901 -m 3d_fullres -f 0 --save_npz\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/bin/nnUNet_predict\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/lib/python3.9/site-packages/nnunet/inference/predict_simple.py\", line 219, in main\n",
      "    predict_from_folder(model_folder_name, input_folder, output_folder, folds, save_npz, num_threads_preprocessing,\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/lib/python3.9/site-packages/nnunet/inference/predict.py\", line 659, in predict_from_folder\n",
      "    return predict_cases(model, list_of_lists[part_id::num_parts], output_files[part_id::num_parts], folds,\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/lib/python3.9/site-packages/nnunet/inference/predict.py\", line 185, in predict_cases\n",
      "    trainer, params = load_model_and_checkpoint_files(model, folds, mixed_precision=mixed_precision,\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/lib/python3.9/site-packages/nnunet/training/model_restore.py\", line 140, in load_model_and_checkpoint_files\n",
      "    trainer = restore_model(join(folds[0], \"%s.model.pkl\" % checkpoint_name), fp16=mixed_precision)\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/lib/python3.9/site-packages/nnunet/training/model_restore.py\", line 56, in restore_model\n",
      "    info = load_pickle(pkl_file)\n",
      "  File \"/home/jc053/miniforge3/envs/mri_post_op_seg/lib/python3.9/site-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/nnUNet_trained_models/nnUNet/3d_fullres/Task901_BraTS2024_PostSurgery/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model.pkl'\n",
      "\n",
      "Inference failed.\n",
      "Inference complete. Results saved in /mnt/93E8-0534/JuanCarlos/BraTS-GLI-2024/organized_dataset/nnUNet_test/inference_results\n"
     ]
    }
   ],
   "source": [
    "INPUT_FOLDER = str(BASE_DIR / MODEL / \"nnUNet_raw_data_base\" /\"nnUNet_raw_data\"/f\"Task{TASK_ID}_{TASK_NAME}\"/\"imagesTs\")\n",
    "OUTPUT_FOLDER = str(BASE_DIR / MODEL / \"inference_results\")\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "inference_command = (\n",
    "    f\"nnUNet_predict -i {INPUT_FOLDER} -o {OUTPUT_FOLDER} \"\n",
    "    f\"-t {TASK_ID} -m 3d_fullres -f 0 --save_npz\"\n",
    ")\n",
    "success = run_command(inference_command)\n",
    "if not success:\n",
    "    print(\"Inference failed.\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Inference complete. Results saved in {OUTPUT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri_post_op_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
